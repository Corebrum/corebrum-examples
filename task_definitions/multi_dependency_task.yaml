task_definition:
  name: "multi_capability_task"
  version: "1.0"
  description: "Task requiring multiple capabilities (python and qwen)"
  inputs: []
  outputs: []
  validation: []
  metadata: {}
  dependencies: ["python", "qwen"]
  
  compute_logic:
    type: "expression"
    language: "python"
    timeout_seconds: 30
    
    code: |
      import json
      import sys
      import time
      
      def simulate_ml_inference(input_text):
          # Simulate Qwen model inference
          # In a real implementation, this would call the Qwen model
          time.sleep(0.1)  # Simulate processing time
          
          # Mock response
          return {
              'input': input_text,
              'response': f"Qwen processed: {input_text}",
              'confidence': 0.95,
              'model': 'qwen-7b'
          }
      
      # Read input from command line arguments
      if len(sys.argv) > 1:
          try:
              input_data = json.loads(sys.argv[1])
          except json.JSONDecodeError:
              input_data = {'text': 'Hello, world!'}
      else:
          input_data = {'text': 'Hello, world!'}
      
      text = input_data.get('text', 'Hello, world!')
      
      # Measure execution time
      start_time = time.time()
      result = simulate_ml_inference(text)
      end_time = time.time()
      
      computation_time_ms = int((end_time - start_time) * 1000)
      
      output = {
          'ml_result': result,
          'computation_time_ms': computation_time_ms,
          'method': 'python_with_qwen',
          'worker_id': 'ml-worker',
          'dependencies_required': ['python', 'qwen'],
          'capabilities_used': ['python', 'qwen'],
          'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
      }
      
      print(json.dumps(output))
    
    input_schema:
      type: "object"
      properties:
        text:
          type: "string"
          description: "Text to process with Qwen model"
      required: ["text"]
